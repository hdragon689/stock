#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon May 19 10:02:21 2025

@author: hdragon689
"""
import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta
import numpy as np
import streamlit as st
import requests
import twstock
import os
import json
import time

# --- Configuration & Constants ---
CRITERIA_KEYS = {
    "pe": "max_pe", "pb": "max_pb", "roe": "min_roe", "eps": "min_eps",
    "div_yield": "min_dividend_yield", "avg_div": "min_avg_dividend_payout_5y",
    "beta": "max_beta"
}
CRITERIA_LABELS_CH = {
    CRITERIA_KEYS["pe"]: "æœ¬ç›Šæ¯” (P/E) ä¸Šé™", CRITERIA_KEYS["pb"]: "è‚¡åƒ¹æ·¨å€¼æ¯” (P/B) ä¸Šé™",
    CRITERIA_KEYS["roe"]: "è‚¡æ±æ¬Šç›Šå ±é…¬ç‡ (ROE) ä¸‹é™ (%)", CRITERIA_KEYS["eps"]: "æ¯è‚¡ç›ˆé¤˜ (EPS) ä¸‹é™",
    CRITERIA_KEYS["div_yield"]: "æ®–åˆ©ç‡ (%) ä¸‹é™", CRITERIA_KEYS["avg_div"]: "è¿‘äº”å¹´å¹³å‡ç¾é‡‘è‚¡åˆ© (å…ƒ) ä¸‹é™",
    CRITERIA_KEYS["beta"]: "Beta (Î²) ä¸Šé™"
}
COLUMN_NAMES_CH = { # These are the keys used internally by yfinance/script BEFORE localization for display
    "Ticker": "è‚¡ç¥¨ä»£è™Ÿ", "Name": "å…¬å¸åç¨±", "Price": "ç›®å‰è‚¡åƒ¹", "P/E": "æœ¬ç›Šæ¯”",
    "P/B": "è‚¡åƒ¹æ·¨å€¼æ¯”", "ROE": "è‚¡æ±æ¬Šç›Šå ±é…¬ç‡ (%)", "EPS": "æ¯è‚¡ç›ˆé¤˜ (EPS)",
    "Div Yield (æ®–åˆ©ç‡)": "æ®–åˆ©ç‡ (%)", "Avg Div 5Y (éå»äº”å¹´å¹³å‡é…æ¯)": "è¿‘äº”å¹´å¹³å‡ç¾é‡‘è‚¡åˆ© (å…ƒ)",
    "Beta": "Beta (Î²)", "Currency": "å¹£åˆ¥", "Market Cap": "å¸‚å€¼"
}
DEFAULT_CRITERIA_VALUES = {
    CRITERIA_KEYS["pe"]: 20.0, CRITERIA_KEYS["pb"]: 2.5, CRITERIA_KEYS["roe"]: 0.15, # ROE as decimal
    CRITERIA_KEYS["eps"]: 1.0, CRITERIA_KEYS["div_yield"]: 0.03, # Div Yield as decimal
    CRITERIA_KEYS["avg_div"]: 0.5, CRITERIA_KEYS["beta"]: 1.2
}

CACHE_DIR = "tempdata"
CACHE_TTL_SECONDS = 12 * 60 * 60
os.makedirs(CACHE_DIR, exist_ok=True)

def save_to_file_cache(filename, data):
    filepath = os.path.join(CACHE_DIR, filename)
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        st.warning(f"ç„¡æ³•å„²å­˜å¿«å–æª”æ¡ˆ {filename}: {e}")

def load_from_file_cache(filename):
    filepath = os.path.join(CACHE_DIR, filename)
    if not os.path.exists(filepath):
        return None
    try:
        file_mod_time = os.path.getmtime(filepath)
        if (time.time() - file_mod_time) > CACHE_TTL_SECONDS:
            os.remove(filepath)
            return None
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    except Exception as e:
        st.warning(f"ç„¡æ³•è®€å–å¿«å–æª”æ¡ˆ {filename}: {e}")
        if os.path.exists(filepath):
            try: os.remove(filepath)
            except Exception: pass
        return None

@st.cache_data(ttl=CACHE_TTL_SECONDS)
def get_sp500_tickers_cached_logic():
    filename = "sp500_tickers.json"
    cached_data = load_from_file_cache(filename)
    if cached_data: return cached_data[0], cached_data[1]
    st.write("æ­£åœ¨ç²å– S&P 500 è‚¡ç¥¨ä»£è™Ÿ (å°‡å­˜å…¥æœ¬åœ°å¿«å–12å°æ™‚)...")
    try:
        url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
        headers = {'User-Agent': 'Mozilla/5.0 (compatible; StockScreenerApp/1.0; +http://localhost)'}
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        payload = pd.read_html(response.text)
        tickers = payload[0]['Symbol'].tolist()
        tickers = [ticker.replace('.', '-') for ticker in tickers]
        names_map = {ticker: "" for ticker in tickers}
        save_to_file_cache(filename, (tickers, names_map))
        return tickers, names_map
    except Exception as e:
        st.error(f"ç²å– S&P 500 è‚¡ç¥¨ä»£è™Ÿå¤±æ•—: {e}")
        return [], {}

@st.cache_data(ttl=CACHE_TTL_SECONDS)
def get_nasdaq100_tickers_cached_logic():
    filename = "nasdaq100_tickers.json"
    cached_data = load_from_file_cache(filename)
    if cached_data: return cached_data[0], cached_data[1]
    st.write("æ­£åœ¨ç²å– NASDAQ 100 è‚¡ç¥¨ä»£è™Ÿ (å°‡å­˜å…¥æœ¬åœ°å¿«å–12å°æ™‚)...")
    try:
        url = 'https://en.wikipedia.org/wiki/Nasdaq-100'
        headers = {'User-Agent': 'Mozilla/5.0 (compatible; StockScreenerApp/1.0; +http://localhost)'}
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        payload = pd.read_html(response.text)
        nasdaq_df = next((df_table for df_table in payload if 'Ticker' in df_table.columns), None)
        if nasdaq_df is not None:
            tickers = nasdaq_df['Ticker'].tolist()
            names_map = {ticker: "" for ticker in tickers}
            save_to_file_cache(filename, (tickers, names_map))
            return tickers, names_map
        st.error("åœ¨ç¶­åŸºç™¾ç§‘é é¢æ‰¾ä¸åˆ° NASDAQ 100 è‚¡ç¥¨ä»£è™Ÿè¡¨ã€‚")
        return [], {}
    except Exception as e:
        st.error(f"ç²å– NASDAQ 100 è‚¡ç¥¨ä»£è™Ÿå¤±æ•—: {e}")
        return [], {}

@st.cache_data(ttl=CACHE_TTL_SECONDS)
def get_tw_market_tickers_cached_logic(market_type_filter):
    filename = f"tw_{market_type_filter}_tickers.json"
    cached_data = load_from_file_cache(filename)
    if cached_data: return cached_data[0], cached_data[1]
    display_market_type = "ä¸Šå¸‚ (TWSE)" if market_type_filter == "ä¸Šå¸‚" else "ä¸Šæ«ƒ (TPEx)"
    st.write(f"æ­£åœ¨ç²å–å°ç£ {display_market_type} å…¬å¸è‚¡ç¥¨ä»£è™ŸåŠåç¨± (å°‡å­˜å…¥æœ¬åœ°å¿«å–12å°æ™‚, é¦–æ¬¡å¯èƒ½è¼ƒä¹…)...")
    try:
        all_stocks = twstock.codes
        if not all_stocks:
            st.warning(f"`twstock.codes` æœªè¿”å›ä»»ä½•è³‡æ–™ ({display_market_type})ã€‚")
            return [], {}
        tw_tickers, tw_names_map = [], {}
        for code, stock_info in all_stocks.items():
            if stock_info and hasattr(stock_info, 'type') and stock_info.type == 'è‚¡ç¥¨' and \
               hasattr(stock_info, 'market') and stock_info.market == market_type_filter and \
               hasattr(stock_info, 'name'):
                ticker_yf = f"{code}.TW"
                tw_tickers.append(ticker_yf)
                tw_names_map[ticker_yf] = stock_info.name
        save_to_file_cache(filename, (tw_tickers, tw_names_map))
        return tw_tickers, tw_names_map
    except Exception as e:
        st.error(f"ä½¿ç”¨ twstock ç²å–å°ç£ {display_market_type} è‚¡ç¥¨ä»£è™Ÿå¤±æ•—: {e}")
        return [], {}

@st.cache_data(ttl=CACHE_TTL_SECONDS)
def get_5yr_avg_dividend_from_cached_data(ticker_symbol_for_cache, dividends_data_for_calc):
    if not dividends_data_for_calc:
        return 0.0
    try:
        if isinstance(dividends_data_for_calc, list) and all(isinstance(item, (list, tuple)) and len(item) == 2 for item in dividends_data_for_calc):
            dividends_dict = {pd.to_datetime(item[0]): item[1] for item in dividends_data_for_calc if item[0] is not None and pd.notna(item[1])}
            if not dividends_dict: dividends = pd.Series(dtype='float64')
            else: dividends = pd.Series(dividends_dict)
        else:
            return 0.0

        if dividends.empty: return 0.0
        end_date_local = datetime.now() 
        start_date_local_naive = end_date_local - timedelta(days=5*365 + 180)
        if dividends.index.tz is not None:
            dividends.index = dividends.index.tz_localize(None)
        start_date_to_compare = pd.Timestamp(start_date_local_naive.year, start_date_local_naive.month, start_date_local_naive.day)
        recent_dividends = dividends[dividends.index >= start_date_to_compare]
        if recent_dividends.empty: return 0.0
        annual_dividends = recent_dividends.groupby(recent_dividends.index.year).sum()
        if annual_dividends.empty: return 0.0
        avg_payout = annual_dividends.tail(5).mean()
        return avg_payout if pd.notna(avg_payout) else 0.0
    except Exception as e:
        return 0.0

@st.cache_data(ttl=CACHE_TTL_SECONDS) 
def get_stock_info_file_cached_logic(ticker_symbol, chinese_name_map): # chinese_name_map is a dict
    safe_ticker_filename = ticker_symbol.replace('.', '_').replace(':', '_')
    filename = f"stockinfo_{safe_ticker_filename}.json"
    
    file_cached_stock_data = load_from_file_cache(filename)
    if file_cached_stock_data is not None:
        return file_cached_stock_data

    try:
        stock = yf.Ticker(ticker_symbol)
        info = stock.info 
        dividends_for_avg_calc = []
        if hasattr(stock, 'dividends') and not stock.dividends.empty:
            dividends_for_avg_calc = [(str(ts.date()), val) for ts, val in stock.dividends.items() if pd.notna(val)]
        if not info or 'symbol' not in info: return None
        avg_div_5y = get_5yr_avg_dividend_from_cached_data(ticker_symbol, dividends_for_avg_calc)
        name_to_use = chinese_name_map.get(ticker_symbol, info.get('shortName') or info.get('longName', ticker_symbol))
        data_to_save = {
            "Ticker": ticker_symbol, "Name": name_to_use,
            "Price": info.get('currentPrice') or info.get('regularMarketPrice') or info.get('previousClose'),
            "P/E": info.get('trailingPE'), "P/B": info.get('priceToBook'),
            "ROE": info.get('returnOnEquity'), "EPS": info.get('trailingEps'),
            "Div Yield (æ®–åˆ©ç‡)": info.get('dividendYield'), # Store as decimal
            "Avg Div 5Y (éå»äº”å¹´å¹³å‡é…æ¯)": avg_div_5y, 
            "Beta": info.get('beta'), "Currency": info.get("currency", "N/A"),
            "Market Cap": info.get("marketCap"),
        }
        save_to_file_cache(filename, data_to_save)
        return data_to_save
    except Exception as e:
        return None

# --- Screen Stocks Function (CORRECTED DataFrame Formatting) ---
def screen_stocks(tickers, criteria_values, active_criteria, progress_bar_st_element, chinese_name_map):
    potential_stocks_data = []
    all_stocks_data = []
    total_tickers = len(tickers)
    processed_count = 0

    for ticker_symbol in tickers:
        processed_count += 1
        if progress_bar_st_element:
            progress_text = f"è™•ç†ä¸­: {ticker_symbol} ({processed_count}/{total_tickers})"
            progress_bar_st_element.progress(processed_count / total_tickers, text=progress_text)
        
        stock_data = get_stock_info_file_cached_logic(ticker_symbol, chinese_name_map) 
        
        if stock_data:
            all_stocks_data.append(stock_data)
            current_stock_passes = True 
            if active_criteria[CRITERIA_KEYS["pe"]]:
                pe_value = stock_data.get("P/E") 
                if pe_value is None: current_stock_passes = False
                elif not (0 < pe_value <= criteria_values[CRITERIA_KEYS["pe"]]): current_stock_passes = False
            if current_stock_passes and active_criteria[CRITERIA_KEYS["pb"]]:
                pb_value = stock_data.get("P/B")
                if pb_value is None: current_stock_passes = False
                elif not (0 < pb_value <= criteria_values[CRITERIA_KEYS["pb"]]): current_stock_passes = False
            if current_stock_passes and active_criteria[CRITERIA_KEYS["roe"]]:
                roe_value = stock_data.get("ROE") 
                if roe_value is None: current_stock_passes = False
                elif roe_value < criteria_values[CRITERIA_KEYS["roe"]]: current_stock_passes = False
            if current_stock_passes and active_criteria[CRITERIA_KEYS["eps"]]:
                eps_value = stock_data.get("EPS")
                if eps_value is None: current_stock_passes = False
                elif eps_value < criteria_values[CRITERIA_KEYS["eps"]]: current_stock_passes = False
            if current_stock_passes and active_criteria[CRITERIA_KEYS["div_yield"]]:
                div_yield_value = stock_data.get("Div Yield (æ®–åˆ©ç‡)") 
                if div_yield_value is None: current_stock_passes = False
                elif div_yield_value < criteria_values[CRITERIA_KEYS["div_yield"]]: current_stock_passes = False
            if current_stock_passes and active_criteria[CRITERIA_KEYS["avg_div"]]:
                avg_div_value = stock_data.get("Avg Div 5Y (éå»äº”å¹´å¹³å‡é…æ¯)")
                if avg_div_value is None: current_stock_passes = False
                elif avg_div_value < criteria_values[CRITERIA_KEYS["avg_div"]]: current_stock_passes = False
            if current_stock_passes and active_criteria[CRITERIA_KEYS["beta"]]:
                beta_value = stock_data.get("Beta")
                if beta_value is None: pass 
                elif beta_value > criteria_values[CRITERIA_KEYS["beta"]]: current_stock_passes = False
            if current_stock_passes:
                potential_stocks_data.append(stock_data)
                
    if progress_bar_st_element:
        progress_bar_st_element.empty()

    df_potential_formatted = pd.DataFrame(potential_stocks_data)
    df_all_formatted = pd.DataFrame(all_stocks_data)
    
    cols_to_format_numeric_standard = ["Price", "P/E", "P/B", "EPS", "Avg Div 5Y (éå»äº”å¹´å¹³å‡é…æ¯)", "Beta"]

    final_dfs = []
    for df_orig in [df_potential_formatted, df_all_formatted]:
        if not df_orig.empty:
            df = df_orig.copy()

            # Convert to numeric first for all relevant columns
            for col in cols_to_format_numeric_standard + ["ROE", "Div Yield (æ®–åˆ©ç‡)"]:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')

            # Apply rounding to non-percentage numeric columns
            for col in cols_to_format_numeric_standard:
                if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):
                    df[col] = df[col].round(2) # Standard 2 decimal places
            
            # Convert ROE and Dividend Yield to percentage values *in their original columns*
            if "ROE" in df.columns and pd.api.types.is_numeric_dtype(df["ROE"]):
                df["ROE"] = (df["ROE"] * 100).round(2)
            
            if "Div Yield (æ®–åˆ©ç‡)" in df.columns and pd.api.types.is_numeric_dtype(df["Div Yield (æ®–åˆ©ç‡)"]):
                df["Div Yield (æ®–åˆ©ç‡)"] = (df["Div Yield (æ®–åˆ©ç‡)"] * 100).round(2)

            if "Market Cap" in df.columns and pd.api.types.is_numeric_dtype(df["Market Cap"]):
                df["Market Cap"] = df["Market Cap"].apply(
                    lambda x: f"{x/1e12:.2f}å…†" if pd.notna(x) and x >= 1e12 else (
                              f"{x/1e8:.2f}å„„" if pd.notna(x) and x >= 1e8 else (
                              f"{x/1e4:.2f}è¬" if pd.notna(x) and x >= 1e4 else (
                              f"{x:.0f}" if pd.notna(x) else "N/A"))))
            
            df.rename(columns=COLUMN_NAMES_CH, inplace=True)
            
            ordered_cols_display_names = [
                COLUMN_NAMES_CH.get("Ticker"), COLUMN_NAMES_CH.get("Name"), 
                COLUMN_NAMES_CH.get("Price"), COLUMN_NAMES_CH.get("P/E"), 
                COLUMN_NAMES_CH.get("P/B"), COLUMN_NAMES_CH.get("ROE"), 
                COLUMN_NAMES_CH.get("EPS"), COLUMN_NAMES_CH.get("Div Yield (æ®–åˆ©ç‡)"),
                COLUMN_NAMES_CH.get("Avg Div 5Y (éå»äº”å¹´å¹³å‡é…æ¯)"), 
                COLUMN_NAMES_CH.get("Beta"), COLUMN_NAMES_CH.get("Market Cap"), 
                COLUMN_NAMES_CH.get("Currency")
            ]
            existing_ordered_cols = [col for col in ordered_cols_display_names if col and col in df.columns]
            
            df = df[existing_ordered_cols]
            final_dfs.append(df)
        else:
            final_dfs.append(pd.DataFrame())
            
    return final_dfs[0], final_dfs[1]

# --- Streamlit App UI ---
def main():
    st.set_page_config(page_title="åƒ¹å€¼è‚¡ç¥¨ç¯©é¸å™¨", layout="wide")
    st.title("ğŸ“ˆ åƒ¹å€¼è‚¡ç¥¨ç¯©é¸å™¨")
    st.markdown("""
    å¾ S&P 500ã€NASDAQ 100ã€å°ç£ä¸Šå¸‚(TWSE)ã€å°ç£ä¸Šæ«ƒ(TPEx)å…¬å¸æˆ–è‡ªè¨‚åˆ—è¡¨ç¯©é¸è‚¡ç¥¨ã€‚
    å¯å‹¾é¸æ¬²å•Ÿç”¨ä¹‹ç¯©é¸æ¢ä»¶ã€‚è³‡æ–™å°‡å„ªå…ˆå¾æœ¬åœ° `tempdata` è³‡æ–™å¤¾å¿«å– (12å°æ™‚æ•ˆæœŸ)ï¼Œå…¶æ¬¡ç‚ºè¨˜æ†¶é«”å¿«å–ã€‚
    """)
    st.sidebar.header("âš™ï¸ ç¯©é¸è¨­å®š")

    market_options_display = {
        "S&P 500 (ç¾åœ‹)": "sp500", "NASDAQ 100 (ç¾åœ‹)": "nasdaq100",
        "å°ç£ä¸Šå¸‚ (TWSE)": "tw_listed", "å°ç£ä¸Šæ«ƒ (TPEx)": "tw_otc",
        "è‡ªè¨‚/å…¶ä»–å°ç£è‚¡ç¥¨åˆ—è¡¨": "custom"
    }
    selected_market_displays = st.sidebar.multiselect(
        "é¸æ“‡å¸‚å ´/æŒ‡æ•¸:", options=list(market_options_display.keys()), default=[]
    )
    selected_markets_internal = [market_options_display[disp] for disp in selected_market_displays]

    custom_tickers_str = ""
    if "custom" in selected_markets_internal:
        st.sidebar.subheader("è‡ªè¨‚/å…¶ä»–å°ç£è‚¡ç¥¨ä»£è™Ÿ")
        custom_tickers_str = st.sidebar.text_area(
            "è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿ (é€—è™Ÿåˆ†éš”)", "2330.TW, 2317.TW", height=100
        )

    st.sidebar.subheader("è²¡å‹™ç¯©é¸æ¢ä»¶ (å‹¾é¸ä»¥å•Ÿç”¨)")
    criteria_values = {}
    active_criteria = {}

    for key_internal_map, label_ch in CRITERIA_LABELS_CH.items():
        active_criteria[key_internal_map] = st.sidebar.checkbox(f"å•Ÿç”¨ {label_ch}", value=True, key=f"cb_{key_internal_map}")
        
        default_val = DEFAULT_CRITERIA_VALUES[key_internal_map]
        min_val_ui = -100.0 if key_internal_map == CRITERIA_KEYS["eps"] else 0.0
        if key_internal_map == CRITERIA_KEYS["pe"] or key_internal_map == CRITERIA_KEYS["pb"]:
            min_val_ui = 0.1
        
        step_val = 0.1
        format_str = "%.1f"
        if key_internal_map == CRITERIA_KEYS["eps"] or key_internal_map == CRITERIA_KEYS["avg_div"]:
            format_str = "%.2f"

        current_val_input = default_val
        label_ui = label_ch
        if key_internal_map == CRITERIA_KEYS["roe"] or key_internal_map == CRITERIA_KEYS["div_yield"]:
            current_val_input = default_val * 100 
            label_ui = label_ch.replace('(%)', '(è¼¸å…¥%å€¼, å¦‚15)')


        user_input = st.sidebar.number_input(
            label_ui, min_value=min_val_ui, value=current_val_input, 
            step=step_val, format=format_str, disabled=not active_criteria[key_internal_map],
            key=f"num_input_{key_internal_map}"
        )
        
        if key_internal_map == CRITERIA_KEYS["roe"] or key_internal_map == CRITERIA_KEYS["div_yield"]:
            criteria_values[key_internal_map] = user_input / 100 
        else:
            criteria_values[key_internal_map] = user_input


    if st.sidebar.button("ğŸš€ é–‹å§‹ç¯©é¸", type="primary"):
        final_tickers_list, master_chinese_name_map = [], {}
        with st.spinner("æ­£åœ¨æº–å‚™è‚¡ç¥¨ä»£è™Ÿåˆ—è¡¨... (æª¢æŸ¥æœ¬åœ°èˆ‡è¨˜æ†¶é«”å¿«å–)"):
            if "sp500" in selected_markets_internal:
                tickers, names = get_sp500_tickers_cached_logic()
                final_tickers_list.extend(tickers); master_chinese_name_map.update(names)
            if "nasdaq100" in selected_markets_internal:
                tickers, names = get_nasdaq100_tickers_cached_logic()
                final_tickers_list.extend(tickers); master_chinese_name_map.update(names)
            if "tw_listed" in selected_markets_internal:
                tickers, names = get_tw_market_tickers_cached_logic(market_type_filter='ä¸Šå¸‚')
                final_tickers_list.extend(tickers); master_chinese_name_map.update(names)
            if "tw_otc" in selected_markets_internal:
                tickers, names = get_tw_market_tickers_cached_logic(market_type_filter='ä¸Šæ«ƒ')
                final_tickers_list.extend(tickers); master_chinese_name_map.update(names)
            if "custom" in selected_markets_internal and custom_tickers_str:
                custom_list = [ticker.strip().upper() for ticker in custom_tickers_str.split(',') if ticker.strip()]
                final_tickers_list.extend(custom_list)
        
        stock_tickers_to_screen = sorted(list(set(final_tickers_list)))
        if not stock_tickers_to_screen:
            st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹å¸‚å ´æˆ–æä¾›è‡ªè¨‚è‚¡ç¥¨ä»£è™Ÿã€‚")
            return

        st.info(f"é–‹å§‹ç¯©é¸ {len(stock_tickers_to_screen)} å€‹ä¸é‡è¤‡çš„è‚¡ç¥¨ä»£è™Ÿ...")
        progress_bar_placeholder = st.empty()
        progress_bar_st_element = progress_bar_placeholder.progress(0, text="åˆå§‹åŒ–...")

        try:
            qualified_df, all_df = screen_stocks(
                stock_tickers_to_screen, criteria_values, active_criteria,
                progress_bar_st_element, master_chinese_name_map
            )
            
            st.subheader(f"ğŸ“Š æ‰€æœ‰å·²ç²å–è³‡æ–™çš„è‚¡ç¥¨ ({len(all_df) if not all_df.empty else 0} æª”)")
            if not all_df.empty: st.dataframe(all_df, use_container_width=True, height=600)
            else: st.write("æœªç²å–ä»»ä½•è‚¡ç¥¨è³‡æ–™ã€‚")

            st.subheader(f"âœ… ç¬¦åˆå·²å•Ÿç”¨ç¯©é¸æ¢ä»¶çš„æ½›åŠ›è‚¡ç¥¨ ({len(qualified_df) if not qualified_df.empty else 0} æª”)")
            if not qualified_df.empty: st.dataframe(qualified_df, use_container_width=True, height=400)
            else: st.write("æ²’æœ‰è‚¡ç¥¨ç¬¦åˆæ‰€æœ‰å·²å•Ÿç”¨çš„ç¯©é¸æ¢ä»¶ã€‚")
            st.success("ç¯©é¸å®Œæˆï¼")
        except Exception as e:
            st.error(f"ç¯©é¸éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            st.exception(e) # Show full traceback for debugging
    else:
        st.info("è«‹åœ¨å´é‚Šæ¬„é¸æ“‡å¸‚å ´ã€è¨­å®šç¯©é¸æ¢ä»¶ï¼Œç„¶å¾Œé»æ“Šã€Œé–‹å§‹ç¯©é¸ã€ã€‚")

    st.sidebar.markdown("---")
    st.sidebar.markdown("æŠ€è¡“æä¾›ï¼š[Streamlit](https://streamlit.io) & [yfinance](https://pypi.org/project/yfinance/) & [twstock](https://github.com/mlouielu/twstock)")
    st.sidebar.markdown("S&P 500/NASDAQ 100ä¾†è‡ªç¶­åŸºç™¾ç§‘ã€‚å°ç£è‚¡ç¥¨åˆ—è¡¨ä¾†è‡ª `twstock`ã€‚æœ¬åœ°æª”æ¡ˆå¿«å–12å°æ™‚ã€‚")

if __name__ == "__main__":
    main()